---
output:
  
  html_document:
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: false
        
  pdf_document:
    
    fig_caption: true
    fig_crop: false
  word_document: default
params:
    printcode: false
---

---
title: "Assignment 2"
author: "ARATHI S"
date: "2024-08-02"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(ISLR)
```

```{r}
library(MASS)
```

1)1. In this exercise you will create some simulated data and will fit simple linear regression models to it. Make sure to use set.seed(1) prior to starting part (a) to ensure consistent results.rnorm

a.	Using the rnorm() function, create a vector, “x”, containing 100 observations drawn from a N(0,1) distribution. This represents a feature, X.

```{r}
set.seed(1)
x=rnorm(100,mean = 0,sd=1)
x
```


b.	Using the rnorm() function, create a vector, “eps”, containing 100 observations drawn from a N(0,0.25) distribution.


```{r}
eps=rnorm(100,mean = 0,sd=sqrt(0.25))
eps
```

c.	Using “x” and “eps”, generate a vector “y” according to the model
Y=−1+0.5X+ε.
What is the length of the vector “y” ? What are the values of β0 and β1 in this linear model ?



```{r}
y = -1+0.5*x+eps
y
```


```{r}
length(y)
```
y=B0=-1
b1 = 0.05


d.	Create a scatterplot displaying the relationship between “x” and “y”. Comment on what you observe.

```{r}
plot(x,y)
```
* x and y has postive liner relastionship between x and y


e.	Fit a least squares linear model to predict “y” using “x”. Comment on the model obtained. How do β^0 and β^1 compare to β0 and β1 ?
```{r}
model_5 = lm(y~x)
model_5
```


```{r}
summary((model_5))
```

* Both are same estimate  and actual beta 0 and beta 1

f.	Display the least squares line on the scatterplot obtained in (d). Draw the population regression line on the plot, in a different color. Use the legend() function to create an appropriate legend.


```{r}
plot(x,y)
abline(model_5,col="red",lty=8)
abline(coef = c(-1,0.5),col="green",,lwd=2)
legend("topleft",c("LR","PR"),col=c("red","green"),lty =c(8,1),lwd = c(2,3))
```


2)This problem involves the “Boston” data set, which we saw in the lab for this chapter. We will now try to predict per capita crime rate using the other variables in this data set. In other words, per capita crime rate is the response, and the other variables are the predictors.


```{r}
data = Boston
```


```{r}
boston = Boston

```


```{r}
Ass_2_1=lm(crim~zn,data = boston)
```


```{r}
summary(Ass_2_1)
```


```{r}
plot(boston$zn,boston$crim)
```

* There is relationship between per captia crime rate and zn, but it is a negative relationship

```{r}
Ass_2_2=lm(crim~indus,data = boston)
summary(Ass_2_2)
```


```{r}
plot(boston$indus,boston$crim)
```

* There is a relationship per captia crime rate and indus has low positive relationship.


```{r}
Ass_2_3=lm(crim~chas,data = boston)
summary(Ass_2_3)
```


```{r}
plot(boston$chas,boston$crim)
```

* per captia crime rate and chas.


```{r}
Ass_2_4=lm(crim~nox,data = boston)
summary(Ass_2_4)
```


```{r}
plot(boston$nox,boston$crim)
```
* There is a positive relationship between per captia crime rate and nox.

```{r}
Ass_2_5=lm(crim~rm,data = boston)
summary(Ass_2_5)
```


```{r}
plot(boston$rm,boston$crim)
```

* There is a negative relationship between per capita crim rate and rm

```{r}
Ass_2_6=lm(crim~age,data = boston)
summary(Ass_2_6)
```


```{r}
plot(boston$age,boston$crim)
```

* between crim and age.

```{r}
Ass_2_7=lm(crim~dis,data = boston)
summary(Ass_2_7)
```


```{r}
plot(boston$dis,boston$crim)
```
 * There is a negative relationship between crim and dis.
 

```{r}
Ass_2_8=lm(crim~rad,data = boston)
summary(Ass_2_8)
```


```{r}
plot(boston$rad,boston$crim)
```

* Between crim and rad

```{r}
Ass_2_9=lm(crim~tax,data = boston)
summary(Ass_2_9)
```


```{r}
plot(boston$tax,boston$crim)
```

* It also has significient relationship.

```{r}
Ass_2_10=lm(crim~ptratio,data = boston)
summary(Ass_2_10)
```


```{r}
plot(boston$ptratio,boston$crim)
```

* There is a positive relationship per capita crim rate and ptratio 

```{r}
Ass_2_11=lm(crim~black,data = boston)
summary(Ass_2_11)
```


```{r}
plot(boston$black,boston$crim)
```



```{r}
Ass_2_12=lm(crim~lstat,data = boston)
summary(Ass_2_12)
```


```{r}
plot(boston$lstat,boston$crim)
```



```{r}
Ass_2_13=lm(crim~medv,data = boston)
summary(Ass_2_13)
```


```{r}
plot(boston$medv,boston$crim)
```

* In conculsion fiting simple linear regression model these are the details we get:  predictors chas is not affecting crime rate. these predictors zn,rm,dis,black,medv increasing it affect’s opposite to means crime rate decrease.if these predictors indus,nox,age,rad,ptratio,lstat increase’s crime rate is also increasing.



b.	Fit a multiple regression model to predict the response using all of the predictors. Describe your results. For which predictors can we reject the null hypothesis H0:βj=0 ?

```{r}
Ass_2_b=lm(crim~.,data = boston)
summary(Ass_2_b)
```

* Fiting multiple regression model zn and black has low signifcient relationship.dis and rad has strong significient relation ship.medv also has significient relationship.
* Using p value we can reject nullhypothesis for these predictors “zn”,“dis”,“rad”,“black”,“medv”.

```{r}
```


```{r}
```


```{r}
```


```{r}
```










